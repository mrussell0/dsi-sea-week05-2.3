{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Pipeline Lab\n",
    "\n",
    "\n",
    "## 1. Data loading\n",
    "In this lab we will create pipelines for data processing on the [Titanic dataset](http://www.kaggle.com/c/titanic-gettingStarted/data).\n",
    "\n",
    "The dataset is a list of passengers. The second column of the dataset is a “label” for each person indicating whether that person survived (1) or did not survive (0). Here is the Kaggle page with more information on the dataset:\n",
    "\n",
    "You can grab the titanic data as follows:\n",
    "\n",
    "    psql -h dsi.c20gkj5cvu3l.us-east-1.rds.amazonaws.com -p 5432 -U dsi_student titanic\n",
    "    password: gastudents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named psycopg2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-28dd2295e620>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msqlalchemy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcreate_engine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mengine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'postgresql://dsi_student:gastudents@dsi.c20gkj5cvu3l.us-east-1.rds.amazonaws.com/titanic'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_sql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'SELECT * FROM train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/work/anaconda/lib/python2.7/site-packages/sqlalchemy/engine/__init__.pyc\u001b[0m in \u001b[0;36mcreate_engine\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'strategy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_strategy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstrategies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategies\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/work/anaconda/lib/python2.7/site-packages/sqlalchemy/engine/strategies.pyc\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, name_or_url, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m                     \u001b[0mdbapi_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpop_kwarg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0mdbapi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdialect_cls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdbapi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdbapi_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mdialect_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dbapi'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdbapi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/work/anaconda/lib/python2.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.pyc\u001b[0m in \u001b[0;36mdbapi\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdbapi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m         \u001b[0;32mimport\u001b[0m \u001b[0mpsycopg2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpsycopg2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named psycopg2"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine('postgresql://dsi_student:gastudents@dsi.c20gkj5cvu3l.us-east-1.rds.amazonaws.com/titanic')\n",
    "\n",
    "df = pd.read_sql('SELECT * FROM train', engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a look at the data using the info method:\n",
    "\n",
    "- Are there numerical features?\n",
    "- Are there categorical features?\n",
    "- Which columns have missing data?\n",
    "- Which of these are important to be filled?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.info()\n",
    "\n",
    "'''\n",
    "The following are the numerical features\n",
    "index          891 non-null int64\n",
    "PassengerId    891 non-null int64\n",
    "Survived       891 non-null int64\n",
    "Pclass         891 non-null int64\n",
    "Age            714 non-null float64\n",
    "SibSp          891 non-null int64\n",
    "Parch          891 non-null int64\n",
    "Fare           891 non-null float64\n",
    "\n",
    "\n",
    "The following are the categorical features\n",
    "Sex            891 non-null object\n",
    "Survived       891 non-null int64\n",
    "Cabin          204 non-null object\n",
    "Embarked       889 non-null object\n",
    "\n",
    "The following contain null values\n",
    "Age            714 non-null float64\n",
    "Cabin          204 non-null object\n",
    "\n",
    "Age should be filled with a standardized mean.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Age\n",
    "\n",
    "Several passengers are missing data points for age. Impute the missing values so that there are no “NaN” values for age as inputs to your model. Explore the distribution of age and decide how you are going to impute the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.Age.plot(kind = 'hist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.b Age Transformer\n",
    "\n",
    "Create a custom transformer that imputes the age values. Depending on how you have decided to impute missing values, this could involve:\n",
    "\n",
    "- Selecting one or more columns\n",
    "- Filling the NAs using Imputer or a custom strategy\n",
    "- Scaling the Age values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "average_age_titanic   = df[\"Age\"].mean()\n",
    "std_age_titanic       = df[\"Age\"].std()\n",
    "count_nan_age_titanic = df[\"Age\"].isnull().sum()\n",
    "\n",
    "# generate random numbers between (mean - std) & (mean + std)\n",
    "rando = np.random.randint(average_age_titanic - std_age_titanic, \n",
    "                           average_age_titanic + std_age_titanic, \n",
    "                           size = count_nan_age_titanic)\n",
    "\n",
    "# fill NaN values in Age column with random values generated\n",
    "df[\"Age\"][np.isnan(df[\"Age\"])] = rando\n",
    "#convert to int\n",
    "df['Age'] = df['Age'].astype(int)\n",
    "df.Age.plot(kind = 'hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Age'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from sklearn.preprocessing import Imputer, StandardScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "    \n",
    "    def transform(self, X, *_):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            return pd.DataFrame(X[self.columns])[]\n",
    "        else:\n",
    "            raise TypeError(\"This transformer only works with Pandas Dataframes\")\n",
    "    \n",
    "    def fit(self, X, *_):\n",
    "        return self\n",
    "    \n",
    "cs = ColumnSelector('Age')\n",
    "\n",
    "cs.transform(df).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "age_pipe = make_pipeline(ColumnSelector('Age'),\n",
    "                         Imputer(),\n",
    "                         StandardScaler())\n",
    "\n",
    "age_pipe.fit_transform(df)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Age'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "age_pipe.fit_transform(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Categorical Variables\n",
    "\n",
    "`Embarked` and `Pclass` are categorical variables. Use pandas get_dummies function to create dummy columns corresponding to the values.\n",
    "\n",
    "`Embarked` has 2 missing values. Fill them with the most common port of embarkment.\n",
    "\n",
    "Feel free to create a GetDummiesTransformer that wraps around the get_dummies function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.Embarked.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.Embarked = df.Embarked.fillna('S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.get_dummies(pd.DataFrame(df['Embarked'].head()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class GetDummiesTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "    \n",
    "    def transform(self, X, *_):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            return pd.get_dummies(X[self.columns], columns = self.columns)\n",
    "        else:\n",
    "            raise TypeError(\"This transformer only works with Pandas Dataframes\")\n",
    "    \n",
    "    def fit(self, X, *_):\n",
    "        return self\n",
    "    \n",
    "gdt = GetDummiesTransformer(['Embarked'])\n",
    "gdt.fit_transform(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# one_hot_pipe.fit_transform(df.head())\n",
    "\n",
    "one_hot_pipe = GetDummiesTransformer(['Pclass', 'Embarked'])\n",
    "\n",
    "one_hot_pipe.fit_transform(df).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Boolean Columns\n",
    "\n",
    "The `Sex` column only contains 2 values: `male` and `female`. Build a custom transformers that is initialized with one of the values and returns a boolean column with values of `True` when that value is found and `False` otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class TrueFalseTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, flag):\n",
    "        self.flag = flag\n",
    "    \n",
    "    def transform(self, X, *_):\n",
    "        return X == self.flag\n",
    "\n",
    "    def fit(self, X, *_):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gender_pipe = make_pipeline(ColumnSelector('Sex'),\n",
    "                            TrueFalseTransformer('male'))\n",
    "\n",
    "gender_pipe.fit_transform(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Fare\n",
    "\n",
    "The `Fare` attribute can be scaled using one of the scalers from the preprocessing module. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'make_pipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-3a317b6474d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# fare_pipe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m fare_pipe = make_pipeline(ColumnSelector('Fare'),\n\u001b[0m\u001b[1;32m      3\u001b[0m                           StandardScaler())\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfare_pipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'make_pipeline' is not defined"
     ]
    }
   ],
   "source": [
    "# fare_pipe\n",
    "fare_pipe = make_pipeline(ColumnSelector('Fare'),\n",
    "                          StandardScaler())\n",
    "\n",
    "fare_pipe.fit_transform(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Union\n",
    "\n",
    "Use the `make_union` function from the `sklearn.pipeline` modeule to combine all the pipes you have created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# union.fit_transform(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "union = make_union(age_pipe,\n",
    "                   one_hot_pipe,\n",
    "                   gender_pipe,\n",
    "                   fare_pipe)\n",
    "\n",
    "union.fit_transform(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df[[u'Pclass', u'Sex', u'Age', u'SibSp', u'Parch', u'Fare', u'Embarked']]\n",
    "y = df[u'Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = union.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The union you have created is a complete pre-processing pipeline that takes the original titanic dataset and extracts a bunch of features out of it. The last step of this process is to persist the `union` object to disk, so that it can be used again later. The following lines achieve this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import dill\n",
    "import gzip\n",
    "\n",
    "with gzip.open('../../assets/datasets/union.dill.gz', 'w') as fout:\n",
    "    dill.dump(union, fout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus\n",
    "\n",
    "Can you think of a way to engineer an additional boolean feature that keeps track whethere the person is travelling alone or with family?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['Family'] = (df['Parch'] > 0 ) & (df['SibSp'] > 0)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
